# ğŸ“š RAG Pipeline with Multiple Data Sources

This project implements a **Retrieval-Augmented Generation (RAG) pipeline** using **LangChain**, **Google Gemini**, and multiple external data sources such as **PDFs, Wikipedia, and Arxiv**.  
The app is deployed with **Streamlit** and provides an interactive chatbot interface.  
You can try it here
https://rag-pipeline-with-multiple-data-scorces-pblxdxaft8m8gnhc9ejwnz.streamlit.app/

---

## âœ¨ Features
- ğŸ“„ **PDF Loader** â€“ Load and chunk documents (example: `SDE.pdf`).  
- ğŸ” **Vector Store (FAISS)** â€“ Store embeddings of documents for semantic search.  
- ğŸ§  **Embeddings (Gemini)** â€“ Uses Google Generative AI embeddings (`models/gemini-embedding-001`).  
- ğŸŒ **External Tools**  
  - **Wikipedia**: Query and retrieve information from Wikipedia.  
  - **Arxiv**: Retrieve research papers from Arxiv.  
- ğŸ¤– **Agent-based RAG** â€“ Built using LangChainâ€™s `create_tool_calling_agent`.  
- ğŸ› **Streamlit UI** â€“ User-friendly interface with feedback options.  

---

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**  
- **LangChain** (`langchain`, `langchain-community`, `langchain-google-genai`)  
- **FAISS** (`faiss-cpu`)  
- **Streamlit**  
- **Google Gemini API** (via `ChatGoogleGenerativeAI`)  

---

## ğŸ“‚ Project Structure


ğŸ“‚ rag-pipeline-with-multiple-data-sources
â”‚â”€â”€ RAG.py                 # Main application script (Streamlit app)
â”‚â”€â”€ requirements.txt       # Python dependencies
â”‚â”€â”€ README.md              # Project documentation
â”‚â”€â”€ .env                   # API keys (not pushed to GitHub)
â”‚
â”œâ”€â”€ ğŸ“‚ venv/               # Virtual environment (should be in .gitignore)
â”‚
â”œâ”€â”€ ğŸ“‚ data/               # Store input files
â”‚    â””â”€â”€ SDE.pdf           # Example PDF used for RAG
â”‚
â”œâ”€â”€ ğŸ“‚ vector_store/       # Saved FAISS or Chroma DB (optional)
â”‚
â””â”€â”€ ğŸ“‚ .streamlit/         # Streamlit config (if needed)
     â””â”€â”€ config.toml

